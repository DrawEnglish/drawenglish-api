from fastapi import FastAPI
from pydantic import BaseModel
from fastapi.responses import FileResponse
from dotenv import load_dotenv
from openai import OpenAI
import os
import json

# --------------------------------------------------
# 1. í™˜ê²½ ì´ˆê¸°í™”
# --------------------------------------------------
load_dotenv()
client = OpenAI()
app = FastAPI()

# --------------------------------------------------
# 2. ë©”ëª¨ë¦¬ êµ¬ì¡° ì„ ì–¸
# --------------------------------------------------
memory = {
    "characters": [],
    "symbols": []
}

# --------------------------------------------------
# 3. ë¬¸ë²• ì—­í•  â†’ ì‹¬ë³¼ ë§¤í•‘ (subject ì œì™¸)
# --------------------------------------------------
role_to_symbol = {
    "verb": "â—‹",
    "object": "â–¡",
    "noun complement": "[",
    "adjective complement": "(",
    "preposition": "â–½",
    "conjunction": "â—‡"
}

# --------------------------------------------------
# 4. ìš”ì²­/ì‘ë‹µ ëª¨ë¸
# --------------------------------------------------
class AnalyzeRequest(BaseModel):
    sentence: str

class AnalyzeResponse(BaseModel):
    sentence: str
    diagramming: str

# --------------------------------------------------
# 5. ë¬¸ì ì €ì¥ + ì´ˆê¸°í™”
# --------------------------------------------------
def store_characters(sentence: str):
    memory["characters"] = list(sentence)
    memory["symbols"] = [" " for _ in memory["characters"]]

# --------------------------------------------------
# 6. GPT ë¬¸ì¥ ë¶„ì„ + í”„ë¡¬í”„íŠ¸ ê°•í™”
# --------------------------------------------------
def gpt_parse(sentence: str):
    prompt = f"""
Analyze the following English sentence.

For each **meaningful word** (excluding punctuation), identify its grammatical role using **only** the following labels:
- subject
- verb
- object
- noun complement
- adjective complement
- preposition
- conjunction

### Instructions:

1. Use 'noun complement' or 'adjective complement' **only** when the word describes:
   - the subject after a linking verb (e.g., "He is a teacher"), or
   - the object in an SVOC structure (e.g., "They elected him president").

2. If the word is a direct or indirect object of a verb (e.g., "They offered us a job"), label it as 'object', **not** as a complement.

3. Do **not** classify determiners like "a", "an", or "the" as prepositions.

4. Do not include punctuation marks in the result.

### Examples:

- He is a teacher. â†’ 'a teacher' = noun complement
- They elected him president. â†’ 'president' = noun complement
- They offered us a job. â†’ 'job' = object âœ…
- The dog chased the cat. â†’ 'dog' = subject, 'chased' = verb, 'cat' = object

Return the result as a JSON array. Each item should be an object with exactly two fields: "word" and "role". Do not include any explanations.

Example:
[
  {{"word": "I", "role": "subject"}},
  {{"word": "love", "role": "verb"}},
  {{"word": "you", "role": "object"}}
]

Sentence: "{sentence}"
"""

    response = client.chat.completions.create(
        model="gpt-4",
        messages=[
            {"role": "system", "content": "You are an expert English grammar analyzer."},
            {"role": "user", "content": prompt}
        ],
        temperature=0
    )

    content = response.choices[0].message.content
    try:
        return json.loads(content)
    except json.JSONDecodeError:
        return []



# --------------------------------------------------
# 7. GPT ê²°ê³¼ ê¸°ë°˜ ì‹¬ë³¼ ì ìš© + í›„ì²˜ë¦¬ ê²€ì¦
# --------------------------------------------------
def apply_symbols(parsed_result):
    char_join = ''.join(memory["characters"]).lower()

    for item in parsed_result:
        word = item.get("word", "").lower()
        role = item.get("role", "").lower()

        # â— í›„ì²˜ë¦¬: ì˜ëª»ëœ preposition ì œê±°
        if role == "preposition" and word in ["a", "an", "the"]:
            continue

        symbol = role_to_symbol.get(role, " ")
        if not symbol.strip():
            continue

        index = char_join.find(word)
        if index != -1:
            memory["symbols"][index] = symbol

# --------------------------------------------------
# 8. ë‹¤ì´ì–´ê·¸ë¨ ìƒì„±
# --------------------------------------------------
def print_diagrams():
    char_line = "".join(memory["characters"])
    symb_line = "".join(memory["symbols"])
    return f"{char_line}\n{symb_line}"

# --------------------------------------------------
# 9. FastAPI /analyze ì—”ë“œí¬ì¸íŠ¸
# --------------------------------------------------
@app.post("/analyze", response_model=AnalyzeResponse)
async def analyze(request: AnalyzeRequest):
    sentence = request.sentence
    store_characters(sentence)
    parsed_result = gpt_parse(sentence)
    apply_symbols(parsed_result)
    diagrams = print_diagrams()

    return {"sentence": sentence, "diagramming": diagrams}

# --------------------------------------------------
# 10. GPTsìš© custom-openapi.json ì œê³µ
# --------------------------------------------------
@app.get("/custom-openapi.json", include_in_schema=False)
async def serve_openapi():
    file_path = os.path.join(os.path.dirname(__file__), "..", "openapi.json")
    return FileResponse(file_path, media_type="application/json")

# --------------------------------------------------
# 11. ì½˜ì†” í…ŒìŠ¤íŠ¸ í•¨ìˆ˜ (ì¶”ê°€ë¨!)
# --------------------------------------------------
def parse_test(sentence: str):
    print("\nğŸŸ¦ ì…ë ¥ ë¬¸ì¥:", sentence)
    
    # 1. ë¬¸ì ì €ì¥
    store_characters(sentence)

    # 2. GPT ë¶„ì„ ê²°ê³¼
    parsed = gpt_parse(sentence)

    # 3. ë¶„ì„ ê²°ê³¼ ì¶œë ¥
    print("\n[ğŸ” Parsed Result]")
    for item in parsed:
        word = item.get("word", "")
        role = item.get("role", "")
        print(f"- {word}: {role}")

    # 4. ì‹¬ë³¼ ì ìš© + ë‹¤ì´ì–´ê·¸ë¨ ì¶œë ¥
    apply_symbols(parsed)
    print("\n[ğŸ–¨ Diagrams]")
    print(print_diagrams())
    import json
    print(json.dumps(parsed, indent=2))

    # return parsed  # ì›í•˜ë©´ ì™¸ë¶€ì—ì„œ ì“¸ ìˆ˜ ìˆë„ë¡ ë°˜í™˜

# ì½˜ì†” ì‹¤í–‰ìš©
if __name__ == "__main__":
    parse_test("I give him a book.")
    parse_test("The weather is beautiful.")
