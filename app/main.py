import os, json, re
import spacy
from fastapi import FastAPI
from fastapi.responses import JSONResponse, FileResponse  # renderì— 10ë¶„ ë‹¨ìœ„ Ping ë³´ë‚´ê¸°ë¥¼ ìœ„í•´ ì¶”ê°€
from pydantic import BaseModel
# ì•„ë˜ api_key= ê¹Œì§€ëŠ” .env íŒŒì¼ì—ì„œ OpenAIí‚¤ë¥¼ ë¶ˆëŸ¬ì˜¤ê¸° ê´€ë ¨ ë¶€ë¶„ 
from openai import OpenAI
from dotenv import load_dotenv

# â— í™˜ê²½ ì„¤ì •
load_dotenv()

api_key = os.getenv("API_KEY") or os.getenv("OPENAI_API_KEY")
if not api_key:
    raise RuntimeError("âŒ OPENAI_API_KEY is not set in environment variables.")
client = OpenAI(api_key=api_key)

app = FastAPI()  # FastAPI() ê°ì²´ë¥¼ ìƒì„±í•´ì„œ ì´í›„ ë¼ìš°íŒ…ì— ì‚¬ìš©
nlp = spacy.load("en_core_web_sm")  # spaCy ê´€ë ¨ ì„¤ì •, (englihs_coreëª¨ë¸_webê¸°ë°˜_small)

# â— ë©”ëª¨ë¦¬ êµ¬ì¡°
memory = {
#    "characters": [],
    "symbols_by_level": {},
}

# â— ì‹¬ë³¼ ë§¤í•‘
role_to_symbol = {
    "verb": "â—‹",
    "object": "â–¡",
    "direct object": "â–¡",
    "indirect object": "â–¡",
    "prepositional object": "â–¡",
    "preposition": "â–½",
    "conjunction": "â—‡"
}

# â— ìš”ì²­/ì‘ë‹µ ëª©ë¡
class AnalyzeRequest(BaseModel):   # ì‚¬ìš©ìê°€ ë³´ë‚¼ ìš”ì²­(sentence) ì •ì˜
    sentence: str

class AnalyzeResponse(BaseModel):  # ì‘ë‹µìœ¼ë¡œ ëŒë ¤ì¤„ ë°ì´í„°(sentence, diagramming) ì •ì˜
    sentence: str
    diagramming: str               # "     â—‹______â–¡__[         "

class ParseRequest(BaseModel):     # spaCy ê´€ë ¨ ì„¤ì •
    text: str

# â— ë¬¸ì ì €ì¥
def init_memorys (sentence: str):
#    memory["characters"] = list(sentence)        # charactersì— sentenceì˜ ê¸€ì í•œê¸€ìì”© ì±„ìš°ê¸°
    memory["symbols_by_level"] = {}  # ë¬¸ì¥ë§ˆë‹¤ ìƒˆë¡œ ì´ˆê¸°í™”
    memory["sentence_length"] = len(sentence)  # ë„ì‹ ê¸¸ì´ ì¶”ì ìš© (ì¤„ ê¸¸ì´ í†µì¼)


# â— GPT íŒŒìŠ¤í•¨ìˆ˜
def gpt_parse(sentence: str):
    prompt = f"""
Analyze the following English sentence and return a JSON array.

Each item must include these 10 fields, in this exact order:
1. "idx" â€“ character index (spaCy token.idx)
2. "text" â€“ the word itself
3. "role" â€“ one of the fixed roles (see below)
4. "combine" â€“ optional; only for main verbs and prepositions
5. "level" â€“ depth in dependency tree

---

ğŸ”¹ Allowed "role" values and their conditions:
- subject: dep_ is "nsubj" or "nsubjpass"
- verb: dep_ is "ROOT" and pos is "VERB", excluding auxiliary verbs (only the main verb per clause)
- object: dep_ is "dobj" or "obj" - SVO
- subject complement: dep_ is "attr" or "acomp" - SVC
- object complement: dep_ is "xcomp", "oprd", or "ccomp" - SVOC
- indirect object: dep_ is "iobj" - SVOO
- direct object: dep_ is "dobj" and "iobj" also exists - SVOO
- preposition: dep_ is "prep"
- prepositional object: dep_ is "pobj"
- conjunction: dep_ is "cc" or "mark"

âŒ Do not invent new roles.  
âŒ Do not use labels like "subject noun complement" or "relative pronoun".  
âŒ If a token doesnâ€™t match any of the above, omit the "role" field.

---

ğŸ”¹ When assigning "combine", only include tokens that meet one of the following structural relationships:

- verb â†’ subject complement       (SVC)
- verb â†’ object                   (SVO)
- verb â†’ indirect object          (SVOO)
- indirect object â†’ direct object (SVOO)
- object â†’ object complement      (SVOC)
- preposition â†’ prepositional object

Each "combine" must reflect an underline connection in DrawEnglish diagrams.  
Do NOT include modifiers, adverbs, prepositions, or conjunctions in "combine".
If none of the above applies, omit the "combine" field entirely.

ğŸ”¹ Level Rules

Assign a "level" value to each token to indicate its structural depth in the sentence.

- level 0: main clause
- level 1+: subordinate clauses, infinitive phrases, or verbals

A new level begins when any of the following structural triggers appears:
- Subordinating conjunctions (e.g., that, because, if)
- Infinitives (to + verb)
- Gerunds (verb-ing)
- Present participles
- Past participles
- Relative pronouns (who, which, that)
- Wh-words (what, why, where, how)
- Compound wh-words (whoever, whatever, however, etc.)

When a new level begins:
- The **first word** (trigger) must be assigned level `n - 0.5`
- All other words in that phrase/clause receive level `n`

This level system is used to separate clauses and reduce visual confusion in sentence diagrams.
Combine links must only occur within the same level.

> âœ… **Optimization Rule:**  
> If the sentence contains **no structural triggers**, assign `"level": 0` to **all items**.  
> You do **not** need to check for deeper structures in that case.


ğŸ”¹ Example format:
[
  {{
    "idx": 5, "text": "elected", "role": "verb", 
    "combine": [ {{ "text": "him", "role": "object" }}, {{ "text": "president", "role": "object complement" }} ],
    "level": 0
  }}
]

---

Sentence: "{sentence}"

Return ONLY the raw JSON array.  
Do not explain anything. Do not include any text outside the array.
"""

    response = client.chat.completions.create(
        model="gpt-4",
        messages=[
            {"role": "system", "content": "You are an expert sentence analyzer."},
            {"role": "user", "content": prompt}
        ],
        temperature=0
    )

    try:
        content = response.choices[0].message.content
#        print("[GPT RESPONSE]", content)  # GPT ì‘ë‹µ ì§ì ‘ í™•ì¸
        return json.loads(content)
    except Exception as e:
        print("[ERROR] GPT parsing failed:", e)
        print("[RAW CONTENT]", content)  # ë¬¸ì œê°€ ëœ ì›ë³¸ ê·¸ëŒ€ë¡œ ì¶œë ¥
        return []


# â— symbols ë©”ëª¨ë¦¬ì— ì‹¬ë³¼ë“¤ ì €ì¥í•˜ê¸°
def apply_symbols(parsed):
    symbols_by_level = memory["symbols_by_level"]
    line_length = memory["sentence_length"]

    for item in parsed:
        idx = item.get("idx", -1)
        role = item.get("role", "").lower()
        pos = item.get("pos", "").upper()
        level = item.get("level")

        if idx < 0 or level is None:
            continue

        # âœ… 0.5ì²˜ëŸ¼ ê²½ê³„ ë ˆë²¨ì€ ë‘ ì¤„ì— ì‹¬ë³¼ ì°ê¸°
        levels = [level]
        if isinstance(level, float) and level % 1 == 0.5:
            levels = [int(level), int(level) + 1]

        # âœ… ë³´ì–´ ì‹¬ë³¼ ê²°ì •
        if role in ["subject complement", "object complement"]:
            if pos in ["NOUN", "PROPN", "PRON"]:
                symbol = "["
            elif pos == "ADJ":
                symbol = "("
            else:
                symbol = None
        else:
            symbol = role_to_symbol.get(role)

        for lvl in levels:
            line = symbols_by_level.setdefault(lvl, [" " for _ in range(line_length)])
            if 0 <= idx < len(line) and line[idx] == " " and symbol:
                line[idx] = symbol



# â— memory["symbols"] ë‚´ìš©ì„ ì¶œë ¥í•˜ê¸° ìœ„í•´ ë§Œë“  í•¨ìˆ˜
def symbols_to_diagram():
    output_lines = []
    for level in sorted(memory["symbols_by_level"]):
        line = ''.join(memory["symbols_by_level"][level])
        output_lines.append(line)
    return '\n'.join(output_lines)


# â— ë””ë²„ê¹…ìš© í…ŒìŠ¤íŠ¸ í•¨ìˆ˜
def test(sentence: str, use_gpt: bool = True):
    print(f"\nğŸ“˜ Sentence: {sentence}")
    if use_gpt:
        parsed = gpt_parse(sentence)
    else:
        parsed = []  # or mock GPT result for offline test
    if not parsed:
        print("âŒ No GPT parsing result.")
    else:
        print("\nğŸ“Š GPT Parsing Result:")
    for item in parsed:
        combine = item.get("combine")
        if combine:
            combine_str = "[" + ', '.join(f"{c.get('text')}:{c.get('role')}" for c in combine) + "]"
        else:
            combine_str = "None"
        print(
            f"â— idx({item.get('idx')}), text({item.get('text')}), role({item.get('role')}), "
            f"combine({combine_str}), level({item.get('level')})"
        )

    print("\nğŸ“˜ spaCy Parsing Result:")
    doc = nlp(sentence)
    for token in doc:
        morph = token.morph.to_dict()
        print(
            f"â— idx({token.idx}), text({token.text}), pos({token.pos_}), tag({token.tag_}), dep({token.dep_}), "
            f"head({token.head.text}), tense({morph.get('Tense')}), form({morph.get('VerbForm')}), "
            f"voice({morph.get('Voice')}), morph({morph})"
        )

    init_memorys(sentence)
    apply_symbols(parsed)
    print("\nğŸ›  Sentence Diagram:")
    index_line = ''.join([str(i % 10) for i in range(len(sentence))])
    print(index_line)
    print(sentence)
    print(symbols_to_diagram())


# ì´ˆê°„ë‹¨ ì„ì‹œ í…ŒìŠ¤íŠ¸1 í•¨ìˆ˜
def test1():
    print(type(symbols_to_diagram()))



# â— ëª¨ë“ˆ ì™¸ë¶€ ì‚¬ìš©ì„ ìœ„í•œ export
__all__ = [
    "init_memorys",
    "gpt_parse"
    "apply_symbols",
    "test"
]

# â— ë¶„ì„ API ì—”ë“œí¬ì¸íŠ¸
@app.post("/analyze", response_model=AnalyzeResponse)  # sentenceë¥¼ ë°›ì•„ "sentence"ì™€ "diagramming" ë¦¬í„´
async def analyze(request: AnalyzeRequest):            # sentenceë¥¼ ë°›ì•„ ë‹¤ìŒ ì²˜ë¦¬ë¡œ ë„˜ê¹€
    init_memorys(request.sentence)                     # ì´ í•¨ìˆ˜ë¡œ ë©”ëª¨ë¦¬ ë‚´ìš© ì±„ì›€ ë˜ëŠ” ì´ˆê¸°í™”
    parsed = gpt_parse(request.sentence)               # GPTì˜ íŒŒì‹±ê²°ê³¼ë¥¼ parsedì— ì €ì¥
    apply_symbols(parsed)                              # parsed ê²°ê³¼ì— ë”°ë¼ ì‹¬ë³¼ë“¤ì„ ë©”ëª¨ë¦¬ì— ì €ì¥ì¥
    return {"sentence": request.sentence, "diagramming": symbols_to_diagram()}

# â— spaCy íŒŒì‹± ê´€ë ¨
@app.post("/parse")
def parse_text(req: ParseRequest):
    doc = nlp(req.text)
    result = []
    for token in doc:
        morph = token.morph.to_dict()
        result.append({
            "idx": token.idx, "text": token.text, "pos": token.pos_, "tag": token.tag_, "dep": token.dep_,
            "head": token.head.text, "tense": morph.get("Tense"), "form": morph.get("VerbForm"),
            "voice": morph.get("Voice"), "morph": morph
        })
    return {"result": result}

# â— ì»¤ìŠ¤í…€ OpenAPI JSON ì œê³µ ì—”ë“œí¬ì¸íŠ¸
# FastAPIì—ì„œ custom-openapi.json ì—”ë“œí¬ì¸íŠ¸ë¥¼ ë§Œë“¤ì–´ì„œ GPTsì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ í•¨.
@app.get("/custom-openapi.json", include_in_schema=False)
async def serve_openapi():
    file_path = os.path.abspath(os.path.join(os.path.dirname(__file__), "..", "openapi.json"))
    # file_path = os.path.join(os.path.dirname(__file__), "..", "openapi.json")
    return FileResponse(file_path, media_type="application/json")

# â— ì•„ë˜ ì—”ë“œí¬ì¸íŠ¸ëŠ” GET /ping ìš”ì²­ì— ëŒ€í•´ {"message": "pong"} ì‘ë‹µì„ ì¤€ë‹¤.
@app.get("/ping")
async def ping():
    return JSONResponse(content={"message": "pong"}, status_code=200)

