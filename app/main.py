import os, json, re
from fastapi import FastAPI  # FastAPIëŠ” Python ê¸°ë°˜ì˜ ì›¹ í”„ë ˆì„ì›Œí¬ë¡œ, Re=EST APIë¥¼ ë§Œë“¤ë•Œ ë§¤ìš° ê°„ë‹¨í•˜ê³  ë¹ ë¦„
from fastapi.responses import JSONResponse  # renderì— 10ë¶„ ë‹¨ìœ„ Ping ë³´ë‚´ê¸°ë¥¼ ìœ„í•´ ì¶”ê°€
from pydantic import BaseModel  # BaseModeld=ì€ FastAPIì—ì„œ request/responseì˜ ë°ì´í„° ê²€ì¦ê³¼ ìë™ ë¬¸ì„œí™”ë¥¼ ìœ„í•´ ì‚¬ìš©ë˜ëŠ” í´ë˜ìŠ¤(Pydanticì œê³µ)
# ì•„ë˜ api_key= ê¹Œì§€ëŠ” .env íŒŒì¼ì—ì„œ OpenAIí‚¤ë¥¼ ë¶ˆëŸ¬ì™€ ì„¤ì •í•˜ëŠ” ë¶€ë¶„ 
from openai import OpenAI
from dotenv import load_dotenv

# 0. í™˜ê²½ ì„¤ì •
load_dotenv()

api_key = os.getenv("API_KEY") or os.getenv("OPENAI_API_KEY")
if not api_key:
    raise RuntimeError("âŒ OPENAI_API_KEY is not set in environment variables.")
client = OpenAI(api_key=api_key)

app = FastAPI()  # FastAPI() ê°ì²´ë¥¼ ìƒì„±í•´ì„œ ì´í›„ ë¼ìš°íŒ…ì— ì‚¬ìš©

# 1. ë©”ëª¨ë¦¬ êµ¬ì¡°
memory = {
    "characters": [],
    "symbols": [],
    "char_lower": "",
    "word_positions": []
}

# 2. ì‹¬ë³¼ ë§¤í•‘
role_to_symbol = {
    "verb": "â—‹",
    "object": "â–¡",
    "subject noun complement": "[",
    "object noun complement": "[",
    "subject adjective complement": "(",
    "object adjective complement": "(",
    "preposition": "â–½",
    "conjunction": "â—‡"
}

# 3. ìš”ì²­/ì‘ë‹µ ëª©ë¡
class AnalyzeRequest(BaseModel):  # ì‚¬ìš©ìê°€ ë³´ë‚¼ ìš”ì²­(sentence) ì •ì˜
    sentence: str

class AnalyzeResponse(BaseModel):  # ì‘ë‹µìœ¼ë¡œ ëŒë ¤ì¤„ ë°ì´í„°(sentence, diagramming) ì •ì˜
    sentence: str
    diagramming: str

# 4. ë¬¸ì ì €ì¥
def store_characters(sentence: str):
    memory["characters"] = list(sentence)
    memory["symbols"] = [" " for _ in sentence]
    memory["char_lower"] = sentence.lower()
    memory["word_positions"] = [
        {"token": m.group(), "index": m.start(), "used": False}
        for m in re.finditer(r'\b\w+\b', memory["char_lower"])
    ]

# 5. GPT íŒŒì‹œí•¨ìˆ˜
def gpt_parse(sentence: str, verbose: bool = True):
    prompt = f"""
Analyze the following English sentence and return a JSON array.

Each item must have:
- \"word\": the word itself
- \"role\": one of:
  [subject, verb, object, subject noun complement, object noun complement, subject adjective complement, object adjective complement, preposition, conjunction]
- (optional) \"combine\": only for main verbs and prepositions. An array of objects with:
  {{ "word": "..." , "role": "..." }}

---

ğŸ”¹ RULES:

1. âœ… Use only **one main verb per clause**.
   - If auxiliary verbs exist (e.g., "will have been eating"), only the final **main verb** ("eating") is labeled `"role": "verb"`.

2. âœ… Use `"combine"` only in these structures:
   - SVO â†’ 1 object
   - SVOO â†’ 2 objects
   - SVOC â†’ object + complement
   - SVC â†’ 1 subject complement
   - SV â†’ âŒ do not include `"combine"` at all

3. âœ… For `"combine"`, only include objects or complements **directly governed by the verb or preposition**.
   - Never include prepositions, modifiers, or adverbs in `"combine"`.
   - Do not include any prepositional phrase or adverbial.

4. âœ… If the object/complement is a **phrase or clause** (e.g., to-infinitive, gerund, participial phrase, that-clause):
   â†’ include only the **first word** of that phrase in the `"combine"` list.

5. âœ… **Prepositions** and their **objects** must be labeled separately.
   - If the preposition governs a noun or noun phrase, it should use `"combine"` to include only the first meaningful noun.
   - Do not include prepositions or their objects in the main verb's `"combine"`.

6. âŒ **Never label these function words** as `"preposition"` or `"object"`:
   - **Articles**: a, an, the
   - **Possessives**: my, your, his, her, its, our, their
   - **Modifiers/Adverbs**: very, really, too, also, quickly, fast, slowly, etc.
   â†’ These should be ignored unless they act as main subject/object/complement.

   ğŸ” Especially:
   - Words like `"fast"`, `"quickly"` must NEVER be labeled as `"object"`.
   - If unsure, label them as `"adverb"` or omit from the JSON.

7. âœ… Conjunctions (e.g., "and", "that", "because") should be labeled `"conjunction"`.

8. âœ… For noun or adjective phrases like "the big red ball" or "my friend", always provide only the **head word** in `"combine"` (e.g., "ball", "friend", not "the ball" or "my friend").

   ğŸ” Examples:
   - Instead of: {{ "word": "the race", "role": "object" }}
     Use:        {{ "word": "race", "role": "object" }}

   - Instead of: {{ "word": "my friend", "role": "subject noun complement" }}
     Use:        {{ "word": "friend", "role": "subject noun complement" }}

9. âœ… In relative clauses (e.g., "The boy who won the race..."), treat the clause as a full SVO structure.
   - Label the verb (e.g., "won") as "verb"
   - Label the object (e.g., "race") as "object"
   - If the verb governs an object/complement, include a proper "combine" list as usual

10. âœ… Relative pronouns (e.g., "who", "which", "that" when referring to nouns) should be labeled "relative pronoun".
   - Do NOT label them as "conjunction".

---

Sentence: "{sentence}"

Return ONLY the raw JSON array. Do not explain anything. Do not include any text outside the array.
"""

    response = client.chat.completions.create(
        model="gpt-4",
        messages=[
            {"role": "system", "content": "You are an expert sentence analyzer."},
            {"role": "user", "content": prompt}
        ],
        temperature=0
    )

    try:
        content = response.choices[0].message.content
        print("[GPT RESPONSE]", content)  # GPT ì‘ë‹µ ì§ì ‘ í™•ì¸
        return json.loads(content)
    except Exception as e:
        print("[ERROR] GPT parsing failed:", e)
        print("[RAW CONTENT]", content)  # ë¬¸ì œê°€ ëœ ì›ë³¸ ê·¸ëŒ€ë¡œ ì¶œë ¥
        return []

# 6. ì‹¬ë³¼ ë° ë°œí–‰ì„  ì ìš©
def apply_symbols(parsed):
    line = memory["char_lower"]
    symbols = memory["symbols"]
    word_positions = memory["word_positions"]

    def find_unused(word):
        for pos in word_positions:
            if pos["token"] == word.lower() and not pos["used"]:
                pos["used"] = True
                return pos["index"]
        return -1

    for item in parsed:
        word = item["word"].lower()
        role = item["role"].lower()
        symbol = role_to_symbol.get(role)
        idx = find_unused(word)
        if symbol and idx != -1 and symbols[idx] == " ":
            symbols[idx] = symbol

        # âœ… combine ì²˜ë¦¬ (ë‹¨, ì „ì¹˜ì‚¬ë‚˜ ì ‘ì¡°ì‚¬ëŠ” ì—°ê²°ì„  ê·¸ë¦¬ì§€ ì•ŠìŒ)
        if role == "verb" and "combine" in item:
            for target in item["combine"]:
                t_word = target["word"].lower()
                t_role = target["role"].lower()

                # â›” ì „ì¹˜ì‚¬, ì ‘ì¡°ì‚¬ëŠ” ì—°ê²°ì„  ì œì™¸
                if t_role in ["preposition", "conjunction"]:
                    continue

                t_symbol = role_to_symbol.get(t_role)
                t_idx = find_unused(t_word)
                if t_idx != -1 and t_symbol and symbols[t_idx] == " ":
                    symbols[t_idx] = t_symbol
                    _connect(symbols, idx, t_idx)

        # âœ… ì „ì¹˜ì‚¬ì— combineì´ ìˆë‹¤ë©´ (ì˜ˆ: on â†’ table)
        if role == "preposition" and "combine" in item:
            for target in item["combine"]:
                t_word = target["word"].lower()
                t_role = target["role"].lower()
                t_symbol = role_to_symbol.get(t_role)
                t_idx = find_unused(t_word)
                if t_idx != -1 and t_symbol and symbols[t_idx] == " ":
                    symbols[t_idx] = t_symbol
                    _connect(symbols, idx, t_idx)

    # âœ… ì¼ë°˜ì ì¸ ì „ì¹˜ì‚¬ + ëª©ì ì— ê´€í•œ êµ¬ì¡° ì²˜ë¦¬ (combine ì—†ì´ ë‚˜ì˜¤ëŠ” ê²½ìš° ëŒ€ë¹„)
    for i in range(len(parsed) - 1):
        cur, nxt = parsed[i], parsed[i + 1]
        if cur["role"] == "preposition" and nxt["role"] == "object":
            c_idx = find_unused(cur["word"])
            n_idx = find_unused(nxt["word"])
            if c_idx != -1 and symbols[c_idx] == " ":
                symbols[c_idx] = role_to_symbol["preposition"]
            if n_idx != -1 and symbols[n_idx] == " ":
                symbols[n_idx] = role_to_symbol["object"]
            if c_idx != -1 and n_idx != -1:
                _connect(symbols, c_idx, n_idx)

# 7. ì—°ê²° í•¨ìˆ˜
def _connect(symbols, start, end):
    if start > end:
        start, end = end, start
    for i in range(start + 1, end):
        if symbols[i] == " ":
            symbols[i] = "_"

# 8. Ã# 8. \xcd9cë ¥ í•¨ìˆ˜
def print_diagram():
    diagram = diagram_filter_clean(memory["symbols"])  
    return f"\n{''.join(memory['characters'])}\n{''.join(diagram)}\n"  
    #â—‡,â–½í›„ 1ì¹¸ ë³´ì • í•„ìš” ì—†ì„ì‹œ ìœ„ 2ì¤„ì€ ì•„ë˜ 1ì¤„ë¡œ ì¹˜í™˜
    #return f"\n{''.join(memory['characters'])}\n{''.join(memory['symbols'])}\n"


# 8-1. ì¶œë ¥ ë³µì§€ í•¨ìˆ˜ (â—‡, â–½ ë’¤ 1ì¹¸ ë¬´ì‹œ) #â—‡,â–½í›„ 1ì¹¸ ë³´ì • í•„ìš” ì—†ì„ì‹œ ì´ í•¨ìˆ˜ ì „ì²´ í•„ìš” ì—†ìŒìŒ
def diagram_filter_clean(diagram):
    cleaned = []
    skip_next = False
    for ch in diagram:
        if skip_next:
            skip_next = False
            continue
        cleaned.append(ch)
        if ch in {'â–½', 'â—‡'}:
            skip_next = True
    return cleaned

# 9. ë””ë²„ê¹…ìš© í…ŒìŠ¤íŠ¸ í•¨ìˆ˜
def test(sentence: str, verbose: bool = True):
    if not verbose:
        import builtins
        builtins.print = lambda *args, **kwargs: None

    print("\n==============================")
    print("ğŸ”¹ ì…ë ¥ ë¬¸ì¥:", sentence)

    store_characters(sentence)
    parsed = gpt_parse(sentence, verbose=verbose)

    print("\nğŸ“Š Parsed JSON:")
    print(json.dumps(parsed, indent=2))

    apply_symbols(parsed)

    print("\nğŸ”¨ Diagram:")
    print(print_diagram())

    print("\nğŸ”¢ ì¸ë±ìŠ¤:")
    index_line = ''.join([str(i % 10) for i in range(len(memory['characters']))])
    print(index_line)
    print(''.join(memory['characters']))
    print(''.join(memory['symbols']))

    print("\nğŸ” ë‹¨ì–´ ìœ„ì¹˜:")
    for pos in memory["word_positions"]:
        print(f"- {pos['token']:10s} at index {pos['index']}")

    print("==============================\n")

# 10. ëª¨ë“ˆ ì™¸ë¶€ ì‚¬ìš©ì„ ìœ„í•œ export
__all__ = [
    "store_characters",
    "gpt_parse",
    "apply_symbols",
    "print_diagram",
    "test"
]

# 11. ë¶„ì„ API ì—”ë“œí¬ì¸íŠ¸
@app.post("/analyze", response_model=AnalyzeResponse)  # ë¬¸ì¥ì„ ë°›ì•„ì„œ ê·¸ì— ëŒ€í•œ "ë¬¸ì¥ êµ¬ì¡°ë„(ë‹¤ì´ì–´ê·¸ë¨)"ë¥¼ ì‘ë‹µìœ¼ë¡œ ë¦¬í„´
async def analyze(request: AnalyzeRequest):
    store_characters(request.sentence)
    parsed = gpt_parse(request.sentence)
    apply_symbols(parsed)
    return {"sentence": request.sentence, "diagramming": print_diagram()}

# 12. ì»¤ìŠ¤í…€ OpenAPI JSON ì œê³µ ì—”ë“œí¬ì¸íŠ¸
# FastAPIì—ì„œ custom-openapi.json ì—”ë“œí¬ì¸íŠ¸ë¥¼ ë§Œë“¤ì–´ì„œ GPTsì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ í•¨.
@app.get("/custom-openapi.json", include_in_schema=False)
async def serve_openapi():
    file_path = os.path.abspath(os.path.join(os.path.dirname(__file__), "..", "openapi.json"))
    # file_path = os.path.join(os.path.dirname(__file__), "..", "openapi.json")
    return FileResponse(file_path, media_type="application/json")

# ì•„ë˜ ì—”ë“œí¬ì¸íŠ¸ëŠ” GET /ping ìš”ì²­ì— ëŒ€í•´ {"message": "pong"} ì‘ë‹µì„ ì¤€ë‹¤.
@app.get("/ping")
async def ping():
    return JSONResponse(content={"message": "pong"}, status_code=200)

#if __name__ == "__main__":
#    import uvicorn
#    uvicorn.run("app.main:app", host="0.0.0.0", port=int(os.environ.get("PORT", 8080)))

