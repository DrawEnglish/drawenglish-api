from fastapi import FastAPI
from pydantic import BaseModel
from fastapi.responses import FileResponse
from dotenv import load_dotenv
from openai import OpenAI
import os
import json

# --------------------------------------------------
# 1. í™˜ê²½ ì´ˆê¸°í™”
# --------------------------------------------------
load_dotenv()
client = OpenAI()
app = FastAPI()

# --------------------------------------------------
# 2. ë©”ëª¨ë¦¬ êµ¬ì¡° ì„ ì–¸
# --------------------------------------------------
memory = {
    "characters": [],
    "symbols": []
}

# --------------------------------------------------
# 3. ë¬¸ë²• ì—­í•  â†’ ì‹¬ë³¼ ë§¤í•‘ (subject ì œì™¸)
# --------------------------------------------------
role_to_symbol = {
    "verb": "â—‹",
    "object": "â–¡",
    "noun complement": "[",
    "adjective complement": "(",
    "preposition": "â–½",
    "conjunction": "â—‡"
}

# --------------------------------------------------
# 4. ìš”ì²­/ì‘ë‹µ ëª¨ë¸
# --------------------------------------------------
class AnalyzeRequest(BaseModel):
    sentence: str

class AnalyzeResponse(BaseModel):
    sentence: str
    diagramming: str

# --------------------------------------------------
# 5. ë¬¸ì ì €ì¥ + ì´ˆê¸°í™”
# --------------------------------------------------
def store_characters(sentence: str):
    memory["characters"] = list(sentence)
    memory["symbols"] = [" " for _ in memory["characters"]]

# --------------------------------------------------
# 6. GPT ë¬¸ì¥ ë¶„ì„ + í”„ë¡¬í”„íŠ¸ ê°•í™”
# --------------------------------------------------
def gpt_parse(sentence: str):
    prompt = f"""
Analyze the following English sentence.

For each meaningful word (excluding punctuation), identify its grammatical role using the following labels:
- subject
- verb
- object
- noun complement
- adjective complement
- preposition
- conjunction

âš ï¸ Do NOT classify determiners such as "a", "an", or "the" as prepositions.

Return the result as a JSON array in this format:
[
  {{"word": "word", "role": "verb"}},
  ...
]

Sentence: "{sentence}"
"""
    response = client.chat.completions.create(
        model="gpt-4",
        messages=[
            {"role": "system", "content": "You are an expert English grammar analyzer."},
            {"role": "user", "content": prompt}
        ],
        temperature=0
    )
    content = response.choices[0].message.content
    try:
        return json.loads(content)
    except json.JSONDecodeError:
        return []

# --------------------------------------------------
# 7. GPT ê²°ê³¼ ê¸°ë°˜ ì‹¬ë³¼ ì ìš© + í›„ì²˜ë¦¬ ê²€ì¦
# --------------------------------------------------
def apply_symbols(parsed_result):
    text = ''.join(memory["characters"]).lower()

    for item in parsed_result:
        word = item.get("word", "").lower()
        role = item.get("role", "").lower()

        # â— í›„ì²˜ë¦¬: ì˜ëª»ëœ preposition ì œê±°
        if role == "preposition" and word in ["a", "an", "the"]:
            continue

        symbol = role_to_symbol.get(role, " ")
        if not symbol.strip():
            continue

        index = text.find(word)
        if index != -1:
            memory["symbols"][index] = symbol

# --------------------------------------------------
# 8. ë‹¤ì´ì–´ê·¸ë¨ ìƒì„±
# --------------------------------------------------
def generate_diagram():
    char_line = "".join(memory["characters"])
    symb_line = "".join(memory["symbols"])
    return f"{char_line}\n{symb_line}"

# --------------------------------------------------
# 9. FastAPI /analyze ì—”ë“œí¬ì¸íŠ¸
# --------------------------------------------------
@app.post("/analyze", response_model=AnalyzeResponse)
async def analyze(request: AnalyzeRequest):
    sentence = request.sentence
    store_characters(sentence)
    parsed_result = gpt_parse(sentence)
    apply_symbols(parsed_result)
    diagram = generate_diagram()

    return {"sentence": sentence, "diagramming": diagram}

# --------------------------------------------------
# 10. GPTsìš© custom-openapi.json ì œê³µ
# --------------------------------------------------
@app.get("/custom-openapi.json", include_in_schema=False)
async def serve_openapi():
    file_path = os.path.join(os.path.dirname(__file__), "..", "openapi.json")
    return FileResponse(file_path, media_type="application/json")

# --------------------------------------------------
# 11. ì½˜ì†” í…ŒìŠ¤íŠ¸ í•¨ìˆ˜ (ì¶”ê°€ë¨!)
# --------------------------------------------------
def test(sentence: str):
    print("\nğŸŸ¦ ì…ë ¥ ë¬¸ì¥:", sentence)
    
    # 1. ë¬¸ì ì €ì¥
    store_characters(sentence)

    # 2. GPT ë¶„ì„ ê²°ê³¼
    parsed = gpt_parse(sentence)

    # 3. ë¶„ì„ ê²°ê³¼ ì¶œë ¥
    print("\n[ğŸ” Parsed Result]")
    for item in parsed:
        word = item.get("word", "")
        role = item.get("role", "")
        print(f"- {word}: {role}")

    # 4. ì‹¬ë³¼ ì ìš© + ë‹¤ì´ì–´ê·¸ë¨ ì¶œë ¥
    apply_symbols(parsed)
    print("\n[ğŸ–¨ Diagram]")
    print(generate_diagram())

    return parsed  # ì›í•˜ë©´ ì™¸ë¶€ì—ì„œ ì“¸ ìˆ˜ ìˆë„ë¡ ë°˜í™˜

# ì½˜ì†” ì‹¤í–‰ìš©
if __name__ == "__main__":
    test("I give him a book.")
    test("The weather is beautiful.")
